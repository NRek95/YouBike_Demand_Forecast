{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_k1_OBlid-e",
        "outputId": "9c6071e0-066b-4451-c358-6a6096ad08ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7m2ULOrWhf5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "77afd819-d249-4a5b-a734-4acf6f6f5077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Consolidating and Cleaning Site Information ---\n",
            "Loaded 391601 records from 261 site files.\n",
            "Created a clean lookup table with 1613 unique stations.\n",
            "\n",
            "--- Step 2: Loading and Resampling Snapshot Data ---\n",
            "Loaded 41137128 snapshot records from 416 files.\n",
            "Resampling snapshot data to 10-minute intervals...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'mday'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mday'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56201639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resampling snapshot data to 10-minute intervals...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mresampled_slots_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_station_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslots_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation_id_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'10T'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resampling complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-56201639.py\u001b[0m in \u001b[0;36mresample_station_data\u001b[0;34m(df, station_id_col, timestamp_col, freq)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mResamples\u001b[0m \u001b[0mirregular\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mseries\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbike\u001b[0m \u001b[0mstations\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfixed\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestamp_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestamp_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mday'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def resample_station_data(df: pd.DataFrame, station_id_col: str, timestamp_col: str, freq: str = '10T') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Resamples irregular time-series data from bike stations to a fixed frequency.\n",
        "    \"\"\"\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
        "    df = df.set_index(timestamp_col)\n",
        "\n",
        "    def get_closest(x):\n",
        "        if x.empty:\n",
        "            return np.nan\n",
        "        target_timestamp = x.name\n",
        "        closest_index = (x.index - target_timestamp).to_series().abs().idxmin()\n",
        "        return x.loc[closest_index]\n",
        "\n",
        "    resampled_dfs = []\n",
        "    for station_id, station_df in tqdm(df.groupby(station_id_col), desc=\"Resampling stations\"):\n",
        "        resampled = station_df.resample(freq).apply(get_closest)\n",
        "        resampled = resampled.ffill().bfill()\n",
        "        resampled[station_id_col] = station_id\n",
        "        resampled_dfs.append(resampled)\n",
        "\n",
        "    final_df = pd.concat(resampled_dfs).reset_index()\n",
        "    # Ensure original timestamp column name is used in the output\n",
        "    final_df = final_df.rename(columns={'index': timestamp_col})\n",
        "    cols = [station_id_col, timestamp_col] + [c for c in final_df.columns if c not in [station_id_col, timestamp_col]]\n",
        "    return final_df[cols]\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = '/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data_clean/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- 1. Process and Clean Site Information ---\n",
        "print(\"--- Step 1: Consolidating and Cleaning Site Information ---\")\n",
        "site_files = glob.glob(os.path.join(DATA_DIR, '*_site.csv'))\n",
        "\n",
        "if not site_files:\n",
        "    print(f\"Error: No site files found in '{DATA_DIR}'.\")\n",
        "else:\n",
        "    all_sites_df = pd.concat((pd.read_csv(file) for file in site_files), ignore_index=True)\n",
        "    print(f\"Loaded {len(all_sites_df)} records from {len(site_files)} site files.\")\n",
        "    all_sites_df = all_sites_df.drop(columns=['sarea', 'ar'])\n",
        "    sites_info_df = all_sites_df.sort_values('sno').drop_duplicates(subset='sno', keep='last').copy()\n",
        "    print(f\"Created a clean lookup table with {len(sites_info_df)} unique stations.\")\n",
        "\n",
        "# --- 2. Load and Resample Time-Series Snapshot Data ---\n",
        "print(\"\\n--- Step 2: Loading and Resampling Snapshot Data ---\")\n",
        "slot_files = glob.glob(os.path.join(DATA_DIR, '*_slot.csv'))\n",
        "\n",
        "if not slot_files:\n",
        "    print(f\"Error: No snapshot/slot files found in '{DATA_DIR}'.\")\n",
        "else:\n",
        "    all_slots_list = [pd.read_csv(file) for file in slot_files]\n",
        "    slots_df = pd.concat(all_slots_list, ignore_index=True)\n",
        "    print(f\"Loaded {len(slots_df)} snapshot records from {len(slot_files)} files.\")\n",
        "\n",
        "    # --- DEBUGGING STEP ---\n",
        "    # Print the columns of the loaded dataframe to confirm the name\n",
        "    print(\"Columns found in the snapshot data:\", slots_df.columns.tolist())\n",
        "\n",
        "    print(\"Resampling snapshot data to 10-minute intervals...\")\n",
        "    # --- THE FIX IS HERE ---\n",
        "    # The timestamp column is 'infoTime', not 'mday'.\n",
        "    resampled_slots_df = resample_station_data(slots_df, station_id_col='sno', timestamp_col='infoTime', freq='10T')\n",
        "    print(\"Resampling complete.\")\n",
        "\n",
        "# --- 3. Perform the Final Merge and Save ---\n",
        "print(\"\\n--- Step 3: Merging Site Info with Resampled Snapshot Data ---\")\n",
        "if 'resampled_slots_df' in locals() and 'sites_info_df' in locals():\n",
        "    site_info_to_merge = sites_info_df[['sno', 'sna', 'tot', 'lat', 'lng']]\n",
        "\n",
        "    # Rename 'infoTime' to 'mday' for consistency if you prefer\n",
        "    resampled_slots_df = resampled_slots_df.rename(columns={'infoTime': 'mday'})\n",
        "\n",
        "    final_df = pd.merge(resampled_slots_df, site_info_to_merge, on='sno', how='left')\n",
        "    final_df = final_df.sort_values(by=['sno', 'mday']).reset_index(drop=True)\n",
        "\n",
        "    print(\"Merge complete. Master dataset is ready.\")\n",
        "    print(\"\\nPreview of the final consolidated DataFrame:\")\n",
        "    print(final_df.head())\n",
        "\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'consolidated_youbike_data_processed.csv')\n",
        "    final_df.to_csv(output_path, index=False)\n",
        "    print(f\"\\nMaster dataset has been saved to: '{output_path}'\")\n",
        "else:\n",
        "    print(\"\\nHalting script because one or both data sources could not be loaded or processed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc1ca7cc",
        "outputId": "d583cd7c-9fdd-40f1-fbb7-db5edeef135c"
      },
      "source": [
        "!pip install --upgrade translators"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting translators\n",
            "  Downloading translators-6.0.1-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from translators) (0.28.1)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from translators) (2.32.4)\n",
            "Collecting niquests>=3.14.0 (from translators)\n",
            "  Downloading niquests-3.15.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting exejs>=0.0.4 (from translators)\n",
            "  Downloading exejs-0.0.6-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: lxml>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from translators) (5.4.0)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from translators) (4.67.1)\n",
            "Collecting pathos>=0.3.4 (from translators)\n",
            "  Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting cloudscraper>=1.2.71 (from translators)\n",
            "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: cryptography>=42.0.4 in /usr/local/lib/python3.12/dist-packages (from translators) (43.0.3)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.12/dist-packages (from cloudscraper>=1.2.71->translators) (3.2.3)\n",
            "Requirement already satisfied: requests-toolbelt>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from cloudscraper>=1.2.71->translators) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=42.0.4->translators) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->translators) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->translators) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->translators) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->translators) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->translators) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.14.0->translators) (3.4.3)\n",
            "Collecting urllib3-future<3,>=2.13.903 (from niquests>=3.14.0->translators)\n",
            "  Downloading urllib3_future-2.13.906-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting wassima<3,>=1.0.1 (from niquests>=3.14.0->translators)\n",
            "  Downloading wassima-2.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting ppft>=1.7.7 (from pathos>=0.3.4->translators)\n",
            "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos>=0.3.4->translators)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos>=0.3.4->translators)\n",
            "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos>=0.3.4->translators)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->translators) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=42.0.4->translators) (2.22)\n",
            "Collecting jh2<6.0.0,>=5.0.3 (from urllib3-future<3,>=2.13.903->niquests>=3.14.0->translators)\n",
            "  Downloading jh2-5.0.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting qh3<2.0.0,>=1.5.4 (from urllib3-future<3,>=2.13.903->niquests>=3.14.0->translators)\n",
            "  Downloading qh3-1.5.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->translators) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->translators) (4.15.0)\n",
            "Downloading translators-6.0.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exejs-0.0.6-py3-none-any.whl (11 kB)\n",
            "Downloading niquests-3.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.1/167.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3_future-2.13.906-py3-none-any.whl (670 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.9/670.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wassima-2.0.1-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.8/145.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jh2-5.0.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (393 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.4/393.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qh3-1.5.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wassima, qh3, ppft, pox, jh2, exejs, dill, urllib3-future, multiprocess, pathos, niquests, cloudscraper, translators\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudscraper-1.2.71 dill-0.4.0 exejs-0.0.6 jh2-5.0.9 multiprocess-0.70.18 niquests-3.15.2 pathos-0.3.4 pox-0.3.6 ppft-1.7.7 qh3-1.5.4 translators-6.0.1 urllib3-future-2.13.906 wassima-2.0.1\n"
          ]
        }
      ]
    }
  ]
}