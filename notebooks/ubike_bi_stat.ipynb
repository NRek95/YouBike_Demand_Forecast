{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg119AHq6CAp",
        "outputId": "7a6883b5-f7d9-4073-e0e9-455ddaba5282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted successfully.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Google Drive Access\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import requests\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✅ Google Drive mounted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktK2X3appMky"
      },
      "outputs": [],
      "source": [
        "# Add this new cell near the top of your notebook\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def calculate_all_metrics(y_true, y_pred):\n",
        "    \"\"\"Calculates MAE, MSE, RMSE, and R-squared.\"\"\"\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R2 score requires multi-output='uniform_average' for multi-dimensional arrays\n",
        "    r2 = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    return mae, mse, rmse, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4tJnRihyLD9",
        "outputId": "81c3b370-8569-4373-b522-b4f32d0f2ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: node2vec in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (4.3.3)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (1.5.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from node2vec) (4.67.1)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Installations\n",
        "!pip install numpy torch networkx node2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5rztQX-ax6b"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Contents of lib/utils.py\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import math\n",
        "\n",
        "def init_seed(seed):\n",
        "    torch.cuda.cudnn_enabled = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "def metric(pred, label):\n",
        "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
        "        mask = np.not_equal(label, 0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask /= np.mean(mask)\n",
        "        mae = np.abs(np.subtract(pred, label)).astype(np.float32)\n",
        "        rmse = np.square(mae)\n",
        "        mape = np.divide(mae, label)\n",
        "        mae = np.nan_to_num(mae * mask)\n",
        "        mae = np.mean(mae)\n",
        "        rmse = np.nan_to_num(rmse * mask)\n",
        "        rmse = np.sqrt(np.mean(rmse))\n",
        "        mape = np.nan_to_num(mape * mask)\n",
        "        mape = np.mean(mape)\n",
        "    return mae, rmse, mape\n",
        "\n",
        "def seq2instance(data, P, F, H):\n",
        "    num_step, dims = data.shape\n",
        "    num_sample = num_step - H - P - F + 1\n",
        "    x = np.zeros(shape = (num_sample, P, dims))\n",
        "    y = np.zeros(shape = (num_sample, F, dims))\n",
        "    z = np.zeros(shape = (num_sample, H, dims))\n",
        "    for i in range(num_sample):\n",
        "        z[i] = data[i : i + H]\n",
        "        x[i] = data[i + H : i + H + P]\n",
        "        y[i] = data[i + H + P : i + H + P + F]\n",
        "    return z, x, y\n",
        "\n",
        "def loadData(args):\n",
        "    # --- Define the full paths to your data files on Google Drive ---\n",
        "    DRIVE_DATA_PATH = \"/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/\"\n",
        "    data_path = os.path.join(DRIVE_DATA_PATH, 'youbike.npz')\n",
        "    SE_FILE = os.path.join(DRIVE_DATA_PATH, 'SE_youbike.txt')\n",
        "\n",
        "    # --- The rest of the function uses these paths ---\n",
        "    Traffic = np.load(data_path)['data']\n",
        "\n",
        "    print(\"Initial loaded traffic Shape is: \", Traffic.shape)\n",
        "    num_step = Traffic.shape[0]\n",
        "\n",
        "    # train/val/test split\n",
        "    train_steps = round(args.train_ratio * num_step)\n",
        "    test_steps = round(args.test_ratio * num_step)\n",
        "    val_steps = num_step - train_steps - test_steps\n",
        "    train = Traffic[: train_steps]\n",
        "    val = Traffic[train_steps : train_steps + val_steps]\n",
        "    test = Traffic[-test_steps :]\n",
        "\n",
        "    # Z, X, Y -> past, present, future\n",
        "    # We only have one feature, so we squeeze the last dimension for seq2instance\n",
        "    trainZ, trainX, trainY = seq2instance(train.squeeze(-1), args.P, args.F, args.H)\n",
        "    valZ, valX, valY = seq2instance(val.squeeze(-1), args.P, args.F, args.H)\n",
        "    testZ, testX, testY = seq2instance(test.squeeze(-1), args.P, args.F, args.H)\n",
        "\n",
        "    # Normalization (using Z-score on occupancy_ratio)\n",
        "    mean, std = np.mean(trainX), np.std(trainX)\n",
        "    trainX = (trainX - mean) / std\n",
        "    valX = (valX - mean) / std\n",
        "    testX = (testX - mean) / std\n",
        "\n",
        "    # Spatial embedding\n",
        "    with open(SE_FILE, mode = 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        temp = lines[0].split(' ')\n",
        "        N, dims = int(temp[0]), int(temp[1])\n",
        "        SE = np.zeros(shape = (N, dims), dtype = np.float32)\n",
        "        for line in lines[1 :]:\n",
        "            temp = line.split(' ')\n",
        "            index = int(temp[0])\n",
        "            SE[index] = temp[1 :]\n",
        "    print(\"SE Shape is: \", SE.shape)\n",
        "\n",
        "    # Temporal embedding (using 10-minute intervals = 144 steps per day)\n",
        "    steps_per_day = 24 * 60 // 10\n",
        "    dayofweek = np.reshape(np.arange(num_step) // steps_per_day % 7, newshape=(-1, 1))\n",
        "    timeofday = np.reshape(np.arange(num_step) % steps_per_day, newshape=(-1,1))\n",
        "    Time = np.concatenate((dayofweek, timeofday), axis = -1)\n",
        "\n",
        "    # train/val/test for TE\n",
        "    train_time = Time[: train_steps]\n",
        "    val_time = Time[train_steps : train_steps + val_steps]\n",
        "    test_time = Time[-test_steps :]\n",
        "\n",
        "    trainTE = seq2instance(train_time, args.P, args.F, args.H)\n",
        "    trainTE = np.concatenate(trainTE, axis = 1).astype(np.int32)\n",
        "    valTE = seq2instance(val_time, args.P, args.F, args.H)\n",
        "    valTE = np.concatenate(valTE, axis = 1).astype(np.int32)\n",
        "    testTE = seq2instance(test_time, args.P, args.F, args.H)\n",
        "    testTE = np.concatenate(testTE, axis = 1).astype(np.int32)\n",
        "\n",
        "    return (trainZ, trainX, trainTE, trainY, valZ, valX, valTE, valY, testZ, testX, testTE, testY,\n",
        "            SE, mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt5gGl5GbBMn"
      },
      "outputs": [],
      "source": [
        "# Cell 3 (Corrected): Contents of models/common_layer.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math # Make sure math is imported\n",
        "\n",
        "class SpatialTransformerModel(torch.nn.Module):\n",
        "    def __init__(self, K, d):\n",
        "        super(SpatialTransformerModel, self).__init__()\n",
        "        D = K*d\n",
        "        self.FC_q = torch.nn.Linear(2*D, D)\n",
        "        self.FC_k = torch.nn.Linear(2*D, D)\n",
        "        self.FC_v = torch.nn.Linear(2*D, D)\n",
        "        self.FC_o1 = torch.nn.Linear(D, D)\n",
        "        self.FC_o2 = torch.nn.Linear(D, D)\n",
        "        self.K = K\n",
        "        self.d = d\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, X, STE, mask):\n",
        "        X = torch.cat((X, STE), dim=-1)\n",
        "        query = F.relu(self.FC_q(X))\n",
        "        key = F.relu(self.FC_k(X))\n",
        "        value = F.relu(self.FC_v(X))\n",
        "        query = torch.cat(torch.split(query, self.d, dim=-1), dim=0)\n",
        "        key = torch.cat(torch.split(key, self.d, dim=-1), dim=0)\n",
        "        value = torch.cat(torch.split(value, self.d, dim=-1), dim=0)\n",
        "        attention = torch.matmul(query, torch.transpose(key, 2, 3))\n",
        "        attention /= (self.d ** 0.5)\n",
        "        attention = self.softmax(attention)\n",
        "        X = torch.matmul(attention, value)\n",
        "        X = torch.cat(torch.split(X, X.shape[0]//self.K, dim=0), dim=-1)\n",
        "        X = self.FC_o2(F.relu(self.FC_o1(X)))\n",
        "        return X\n",
        "\n",
        "class TemporalTransformerModel(torch.nn.Module):\n",
        "    def __init__(self, K, d):\n",
        "        super(TemporalTransformerModel, self).__init__()\n",
        "        D = K*d\n",
        "        self.FC_q = torch.nn.Linear(2*D, D)\n",
        "        self.FC_k = torch.nn.Linear(2*D, D)\n",
        "        self.FC_v = torch.nn.Linear(2*D, D)\n",
        "        self.FC_o1 = torch.nn.Linear(D, D)\n",
        "        self.FC_o2 = torch.nn.Linear(D, D)\n",
        "        self.K = K\n",
        "        self.d = d\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, X, STE, mask):\n",
        "        X = torch.cat((X, STE), dim=-1)\n",
        "        query = F.relu(self.FC_q(X))\n",
        "        key = F.relu(self.FC_k(X))\n",
        "        value = F.relu(self.FC_v(X))\n",
        "        query = torch.cat(torch.split(query, self.d, dim=-1), dim=0)\n",
        "        key = torch.cat(torch.split(key, self.d, dim=-1), dim=0)\n",
        "        value = torch.cat(torch.split(value, self.d, dim=-1), dim=0)\n",
        "        query = torch.transpose(query, 2, 1)\n",
        "        key = torch.transpose(torch.transpose(key, 1, 2), 2, 3)\n",
        "        value = torch.transpose(value, 2, 1)\n",
        "        attention = torch.matmul(query, key)\n",
        "        attention /= (self.d ** 0.5)\n",
        "        if mask:\n",
        "            batch_size = X.shape[0]\n",
        "            num_step = X.shape[1]\n",
        "            num_vertex = X.shape[2]\n",
        "            mask_tensor = torch.ones(num_step, num_step).to(X.device)\n",
        "            mask_tensor = torch.tril(mask_tensor)\n",
        "            mask_tensor = torch.unsqueeze(torch.unsqueeze(mask_tensor, dim=0), dim=0)\n",
        "            mask_tensor = mask_tensor.repeat(self.K * batch_size, num_vertex, 1, 1)\n",
        "            mask_tensor = mask_tensor.to(torch.bool)\n",
        "            attention = torch.where(mask_tensor, attention, -2 ** 15 + torch.tensor([1],dtype=torch.float32).to(X.device))\n",
        "        attention = self.softmax(attention)\n",
        "        X = torch.matmul(attention, value)\n",
        "        X = torch.transpose(X, 2, 1)\n",
        "        X = torch.cat(torch.split(X, X.shape[0]//self.K, dim=0), dim=-1)\n",
        "        X = self.FC_o2(F.relu(self.FC_o1(X)))\n",
        "        return X\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, flag, hidden_size, num_heads, layer_dropout=0.0, relu_dropout=0.0):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        if flag=='T': self.multi_head_attention = TemporalTransformerModel(num_heads, hidden_size//num_heads)\n",
        "        if flag=='S': self.multi_head_attention = SpatialTransformerModel(num_heads, hidden_size//num_heads)\n",
        "        self.positionwise_feed_forward = PositionwiseFeedForward(hidden_size, hidden_size, hidden_size, layer_config='ll', padding = 'both', dropout=relu_dropout)\n",
        "        self.dropout = nn.Dropout(layer_dropout)\n",
        "        self.layer_norm_mha = LayerNorm(hidden_size)\n",
        "        self.layer_norm_ffn = LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, inputs, STE, mask):\n",
        "        x = inputs\n",
        "        x_norm = self.layer_norm_mha(x)\n",
        "        y = self.multi_head_attention(x_norm, STE, mask)\n",
        "        x = self.dropout(x + y)\n",
        "        x_norm = self.layer_norm_ffn(x)\n",
        "        y = self.positionwise_feed_forward(x_norm)\n",
        "        y = self.dropout(x + y)\n",
        "        return y\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, input_depth, filter_size, output_depth, layer_config='cc', padding='left', dropout=0.0):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        layers = []\n",
        "        sizes = ([(input_depth, filter_size)] + [(filter_size, filter_size)]*(len(layer_config)-2) + [(filter_size, output_depth)])\n",
        "        for lc, s in zip(list(layer_config), sizes):\n",
        "            if lc == 'l': layers.append(nn.Linear(*s))\n",
        "            else: raise ValueError(\"Unknown layer type {}\".format(lc))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if i < len(self.layers):\n",
        "                x = self.relu(x)\n",
        "                x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(features))\n",
        "        self.beta = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "def _gen_embedding(length, channels, min_timescale=1.0, max_timescale=1.0e4):\n",
        "    position = np.arange(length)\n",
        "    num_timescales = channels // 2\n",
        "    log_timescale_increment = ( math.log(float(max_timescale) / float(min_timescale)) / (float(num_timescales) - 1))\n",
        "\n",
        "    # --- THIS LINE IS CORRECTED ---\n",
        "    inv_timescales = min_timescale * np.exp(np.arange(num_timescales).astype(float) * -log_timescale_increment)\n",
        "\n",
        "    scaled_time = np.expand_dims(position, 1) * np.expand_dims(inv_timescales, 0)\n",
        "    signal = np.concatenate([np.sin(scaled_time), np.cos(scaled_time)], axis=1)\n",
        "    signal = np.pad(signal, [[0, 0], [0, channels % 2]], 'constant', constant_values=[0.0, 0.0])\n",
        "    signal =  signal.reshape([1, length, channels])\n",
        "    return torch.from_numpy(signal).type(torch.FloatTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuO8T-c1bNw0"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Contents of models/spatial_adaptive_transformer.py\n",
        "class SpatialAdaptiveTransformer(nn.Module):\n",
        "    def __init__(self, epsilon, flag, hidden_size, max_step, num_heads, seq_length, input_dropout=0.0, layer_dropout=0.0,\n",
        "                 relu_dropout=0.0, dhm=False):\n",
        "        super(SpatialAdaptiveTransformer, self).__init__()\n",
        "        self.position_embedding = _gen_embedding(seq_length, hidden_size)\n",
        "        self.recurrent_embedding = _gen_embedding(max_step, hidden_size)\n",
        "        self.max_step = max_step\n",
        "        self.dhm = dhm\n",
        "        self.att = AttentionLayer(flag, hidden_size, num_heads, layer_dropout, relu_dropout)\n",
        "        self.layer_norm = LayerNorm(hidden_size)\n",
        "        self.input_dropout = nn.Dropout(input_dropout)\n",
        "        if(self.dhm): self.dhm_fn = DHM_basic_Spatial(epsilon, hidden_size)\n",
        "\n",
        "    def forward(self, inputs, STE):\n",
        "        x = self.input_dropout(inputs)\n",
        "        if(self.dhm):\n",
        "            x, (remainders,n_updates) = self.dhm_fn(x, inputs, STE, self.att, self.position_embedding, self.recurrent_embedding, self.max_step)\n",
        "            return x, (remainders,n_updates)\n",
        "        else:\n",
        "            for l in range(self.max_step):\n",
        "                x += self.position_embedding[:, :inputs.shape[1], :].type_as(inputs.data)\n",
        "                x += self.recurrent_embedding[:, l, :].unsqueeze(1).repeat(1,inputs.shape[1],1).type_as(inputs.data)\n",
        "                x = self.att(x, STE, None)\n",
        "            return x, None\n",
        "\n",
        "class DHM_basic_Spatial(nn.Module):\n",
        "    def __init__(self, epsilon, hidden_size):\n",
        "        super(DHM_basic_Spatial, self).__init__()\n",
        "        self.sigma = nn.Sigmoid()\n",
        "        self.p = nn.Linear(hidden_size,1)\n",
        "        self.p.bias.data.fill_(1)\n",
        "        self.threshold = 1 - epsilon\n",
        "\n",
        "    def forward(self, state, inputs, STE, fn, pos_enc, recur_enc, max_step, encoder_output=None):\n",
        "        B,T,N,D = state.shape\n",
        "        device = state.device\n",
        "        state = state.view(B*T,N,D)\n",
        "        inputs = inputs.view(B*T,N,D)\n",
        "        halting_probability = torch.zeros(B*T,N, device=device)\n",
        "        remainders = torch.zeros(B*T,N, device=device)\n",
        "        n_updates = torch.zeros(B*T,N, device=device)\n",
        "        previous_state = torch.zeros_like(inputs, device=device)\n",
        "        step = 0\n",
        "        while( ((halting_probability<self.threshold) & (n_updates < max_step)).byte().any()):\n",
        "            state = state + pos_enc[:, :inputs.shape[1], :].type_as(inputs.data).to(device)\n",
        "            state = state + recur_enc[:, step, :].unsqueeze(1).repeat(1,inputs.shape[1],1).type_as(inputs.data).to(device)\n",
        "            p = self.sigma(self.p(state)).squeeze(-1)\n",
        "            still_running = (halting_probability < 1.0).float()\n",
        "            new_halted = (halting_probability + p * still_running > self.threshold).float() * still_running\n",
        "            still_running = (halting_probability + p * still_running <= self.threshold).float() * still_running\n",
        "            halting_probability += p * still_running\n",
        "            remainders += new_halted * (1 - halting_probability)\n",
        "            halting_probability += new_halted * remainders\n",
        "            n_updates += still_running + new_halted\n",
        "            update_weights = p * still_running + new_halted * remainders\n",
        "            state = state.view(B,T,N,D)\n",
        "            state = fn(state, STE, None)\n",
        "            state = state.view(B*T,N,D)\n",
        "            previous_state = (state * update_weights.unsqueeze(-1)) + (previous_state * (1 - update_weights.unsqueeze(-1)))\n",
        "            step+=1\n",
        "        return previous_state.view(B,T,N,D), (remainders.view(B,T,N), n_updates.view(B,T,N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKmJEYtkbT99"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Contents of models/temporal_adaptive_transformer.py\n",
        "class TemporalAdaptiveTransformer(nn.Module):\n",
        "    def __init__(self, epsilon, flag, hidden_size, max_step, num_heads, seq_length=100, input_dropout=0.0, layer_dropout=0.0,\n",
        "                 relu_dropout=0.0, dhm=False):\n",
        "        super(TemporalAdaptiveTransformer, self).__init__()\n",
        "        self.position_embedding = _gen_embedding(seq_length, hidden_size)\n",
        "        self.recurrent_embedding = _gen_embedding(max_step, hidden_size)\n",
        "        self.max_step = max_step\n",
        "        self.dhm = dhm\n",
        "        self.att = AttentionLayer(flag, hidden_size, num_heads, layer_dropout, relu_dropout)\n",
        "        self.layer_norm = LayerNorm(hidden_size)\n",
        "        self.input_dropout = nn.Dropout(input_dropout)\n",
        "        if(self.dhm): self.dhm_fn = DHM_basic_Temporal(epsilon, hidden_size)\n",
        "\n",
        "    def forward(self, inputs, STE, mask):\n",
        "        x = self.input_dropout(inputs)\n",
        "        if(self.dhm):\n",
        "            x, (remainders,n_updates) = self.dhm_fn(x, inputs, STE, self.att, self.position_embedding, self.recurrent_embedding, self.max_step, mask)\n",
        "            return x, (remainders,n_updates)\n",
        "        else:\n",
        "            for l in range(self.max_step):\n",
        "                x += self.position_embedding[:, :inputs.shape[1], :].type_as(inputs.data)\n",
        "                x += self.recurrent_embedding[:, l, :].unsqueeze(1).repeat(1,inputs.shape[1],1).type_as(inputs.data)\n",
        "                x = self.att(x, STE, mask)\n",
        "            return x, None\n",
        "\n",
        "class DHM_basic_Temporal(nn.Module):\n",
        "    def __init__(self, epsilon, hidden_size):\n",
        "        super(DHM_basic_Temporal, self).__init__()\n",
        "        self.sigma = nn.Sigmoid()\n",
        "        self.p = nn.Linear(hidden_size,1)\n",
        "        self.p.bias.data.fill_(1)\n",
        "        self.threshold = 1 - epsilon\n",
        "\n",
        "    def forward(self, state, inputs, STE, fn, pos_enc, recur_enc, max_step, mask, encoder_output=None):\n",
        "        B,T,N,D = state.shape\n",
        "        device = state.device\n",
        "        state = state.transpose(1,2).reshape(-1,T,D)\n",
        "        inputs = inputs.transpose(1,2).reshape(-1,T,D)\n",
        "        halting_probability = torch.zeros(inputs.shape[0],inputs.shape[1], device=device)\n",
        "        remainders = torch.zeros(inputs.shape[0],inputs.shape[1], device=device)\n",
        "        n_updates = torch.zeros(inputs.shape[0],inputs.shape[1], device=device)\n",
        "        previous_state = torch.zeros_like(inputs, device=device)\n",
        "        step = 0\n",
        "        while( ((halting_probability<self.threshold) & (n_updates < max_step)).byte().any()):\n",
        "            state = state + pos_enc[:, :inputs.shape[1], :].type_as(inputs.data).to(device)\n",
        "            state = state + recur_enc[:, step, :].unsqueeze(1).repeat(1,inputs.shape[1],1).type_as(inputs.data).to(device)\n",
        "            p = self.sigma(self.p(state)).squeeze(-1)\n",
        "            still_running = (halting_probability < 1.0).float()\n",
        "            new_halted = (halting_probability + p * still_running > self.threshold).float() * still_running\n",
        "            still_running = (halting_probability + p * still_running <= self.threshold).float() * still_running\n",
        "            halting_probability += p * still_running\n",
        "            remainders += new_halted * (1 - halting_probability)\n",
        "            halting_probability += new_halted * remainders\n",
        "            n_updates += still_running + new_halted\n",
        "            update_weights = p * still_running + new_halted * remainders\n",
        "            state = state.view(B,N,T,D).transpose(1,2)\n",
        "            state = fn(state, STE, mask)\n",
        "            state = state.transpose(1,2).view(-1,T,D)\n",
        "            previous_state = (state * update_weights.unsqueeze(-1)) + (previous_state * (1 - update_weights.unsqueeze(-1)))\n",
        "            step+=1\n",
        "        return previous_state.view(B,N,T,D).transpose(1,2), (remainders.view(B,N,T), n_updates.view(B,N,T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p98K0NFPbYqh"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Contents of models/model.py\n",
        "class STEmbModel(torch.nn.Module):\n",
        "    def __init__(self, SEDims, TEDims, OutDims, device):\n",
        "        super(STEmbModel, self).__init__()\n",
        "        self.TEDims = TEDims\n",
        "        self.FC_se1 = torch.nn.Linear(SEDims, OutDims)\n",
        "        self.FC_se2 = torch.nn.Linear(OutDims, OutDims)\n",
        "        self.FC_te1 = torch.nn.Linear(TEDims, OutDims)\n",
        "        self.FC_te2 = torch.nn.Linear(OutDims, OutDims)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, SE, TE):\n",
        "        SE = SE.unsqueeze(0).unsqueeze(0)\n",
        "        SE = self.FC_se2(F.relu(self.FC_se1(SE)))\n",
        "        dayofweek = F.one_hot(TE[..., 0], num_classes = 7)\n",
        "        timeofday = F.one_hot(TE[..., 1], num_classes = self.TEDims-7)\n",
        "        TE = torch.cat((dayofweek, timeofday), dim=-1)\n",
        "        TE = TE.unsqueeze(2).type(torch.FloatTensor).to(self.device)\n",
        "        TE = self.FC_te2(F.relu(self.FC_te1(TE)))\n",
        "        sum_tensor = torch.add(SE, TE)\n",
        "        return sum_tensor\n",
        "\n",
        "class EntangleModel(torch.nn.Module):\n",
        "    def __init__(self, K, d):\n",
        "        super(EntangleModel, self).__init__()\n",
        "        D = K*d\n",
        "        self.FC_xs = torch.nn.Linear(D, D)\n",
        "        self.FC_xt = torch.nn.Linear(D, D)\n",
        "        self.FC_h1 = torch.nn.Linear(D, D)\n",
        "        self.FC_h2 = torch.nn.Linear(D, D)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, HS, HT):\n",
        "        XS = self.FC_xs(HS)\n",
        "        XT = self.FC_xt(HT)\n",
        "        z = self.sigmoid(torch.add(XS, XT))\n",
        "        H = torch.add((z* HS), ((1-z)* HT))\n",
        "        H = self.FC_h2(F.relu(self.FC_h1(H)))\n",
        "        return H\n",
        "\n",
        "class STATModel(torch.nn.Module):\n",
        "    def __init__(self, K, d, epsilon, hidden_size, max_step, T, N, dhm):\n",
        "        super(STATModel, self).__init__()\n",
        "        self.spatialAdaptiveTransformer = SpatialAdaptiveTransformer(epsilon, 'S', hidden_size, max_step, K, N, dhm=dhm)\n",
        "        self.temporalAdaptiveTransformer = TemporalAdaptiveTransformer(epsilon, 'T', hidden_size, max_step, K, T, dhm=dhm)\n",
        "        self.entangle = EntangleModel(K, d)\n",
        "\n",
        "    def forward(self, X, STE, mask):\n",
        "        HS, dhm_S = self.spatialAdaptiveTransformer(X, STE)\n",
        "        HT, dhm_T = self.temporalAdaptiveTransformer(X, STE, mask)\n",
        "        H = self.entangle(HS, HT)\n",
        "        return torch.add(X, H), dhm_S, dhm_T\n",
        "\n",
        "class STTModel(torch.nn.Module):\n",
        "    def __init__(self, K, d):\n",
        "        super(STTModel, self).__init__()\n",
        "        self.spatialTransformer = SpatialTransformerModel(K, d)\n",
        "        self.temporalTransformer = TemporalTransformerModel(K, d)\n",
        "        self.entangle = EntangleModel(K, d)\n",
        "\n",
        "    def forward(self, X, STE, mask):\n",
        "        HS = self.spatialTransformer(X, STE, mask)\n",
        "        HT = self.temporalTransformer(X, STE, mask)\n",
        "        H = self.entangle(HS, HT)\n",
        "        return torch.add(X, H)\n",
        "\n",
        "class CrossAttentionModel(torch.nn.Module):\n",
        "    def __init__(self, K, d):\n",
        "        super(CrossAttentionModel, self).__init__()\n",
        "        D = K * d\n",
        "        self.FC_Q_Cross = torch.nn.Linear(D, D)\n",
        "        self.FC_K_Cross = torch.nn.Linear(D, D)\n",
        "        self.FC_V_Cross = torch.nn.Linear(D, D)\n",
        "        self.FC_Out1 = torch.nn.Linear(D, D)\n",
        "        self.FC_Out2 = torch.nn.Linear(D, D)\n",
        "        self.K = K\n",
        "        self.d = d\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, X, STE_P, STE_Q):\n",
        "        query = F.relu(self.FC_Q_Cross(STE_Q))\n",
        "        key = F.relu(self.FC_K_Cross(STE_P))\n",
        "        value = F.relu(self.FC_V_Cross(X))\n",
        "        query = torch.cat(torch.split(query, self.d, dim=-1), dim=0)\n",
        "        key = torch.cat(torch.split(key, self.d, dim=-1), dim=0)\n",
        "        value = torch.cat(torch.split(value, self.d, dim=-1), dim=0)\n",
        "        query = torch.transpose(query, 2, 1)\n",
        "        key = torch.transpose(torch.transpose(key, 1, 2), 2, 3)\n",
        "        value = torch.transpose(value, 2, 1)\n",
        "        attention = torch.matmul(query, key)\n",
        "        attention /= (self.d ** 0.5)\n",
        "        attention = self.softmax(attention)\n",
        "        X = torch.matmul(attention, value)\n",
        "        X = torch.transpose(X, 2, 1)\n",
        "        X = torch.cat(torch.split(X, X.shape[0]//self.K, dim=0), dim=-1)\n",
        "        X = self.FC_Out2(F.relu(self.FC_Out1(X)))\n",
        "        return X\n",
        "\n",
        "class BISTAT(torch.nn.Module):\n",
        "    def __init__(self, K, d, SEDims, TEDims, P, F, H, N, L, episilon, hidden_size, max_hop, dhm, device, input_dims=1):\n",
        "        super(BISTAT, self).__init__()\n",
        "        D = K*d\n",
        "        self.P, self.F, self.H, self.L = P, F, H, L\n",
        "        self.FC_1, self.FC_2 = torch.nn.Linear(input_dims, D), torch.nn.Linear(D, D)\n",
        "        self.STEmb = STEmbModel(SEDims, TEDims, K*d, device)\n",
        "        self.STATBlockEnc = torch.nn.ModuleList([STATModel(K, d, episilon, hidden_size, max_hop, P, N, dhm) for _ in range(self.L)])\n",
        "        self.STATBlockDec1 = torch.nn.ModuleList([STATModel(K, d, episilon, hidden_size, max_hop, F, N, dhm) for _ in range(self.L)])\n",
        "        self.STATBlockDec2 = torch.nn.ModuleList([STTModel(K, d) for _ in range(self.L)])\n",
        "        self.CrossAttention1 = CrossAttentionModel(K, d)\n",
        "        self.CrossAttention2 = CrossAttentionModel(K, d)\n",
        "        self.FC_dec1_1, self.FC_dec1_2 = torch.nn.Linear(D, D), torch.nn.Linear(D, 1)\n",
        "        self.FC_dec2_1, self.FC_dec2_2 = torch.nn.Linear(D, D), torch.nn.Linear(D, 1)\n",
        "\n",
        "    def forward(self, X, SE, TE, flag):\n",
        "        # Add the feature dimension back before the first layer\n",
        "        X = X.unsqueeze(3)\n",
        "\n",
        "        X = self.FC_2(F.relu(self.FC_1(X)))\n",
        "        STE = self.STEmb(SE, TE)\n",
        "        STE_H, STE_P, STE_F = STE[:, :self.H], STE[:, self.H:self.H+self.P], STE[:, self.H+self.P:]\n",
        "\n",
        "        dhm0_S_enc, dhm1_S_enc, dhm0_T_enc, dhm1_T_enc = [], [], [], []\n",
        "\n",
        "        X, dhm_S, dhm_T = self.STATBlockEnc[0](X, STE_P, mask=True)\n",
        "\n",
        "        dhm0_S_enc.append(dhm_S[0]); dhm1_S_enc.append(dhm_S[1]); dhm0_T_enc.append(dhm_T[0]); dhm1_T_enc.append(dhm_T[1])\n",
        "        X_enc_out_L1 = X\n",
        "\n",
        "        for l in range(1, self.L):\n",
        "            X, dhm_S, dhm_T = self.STATBlockEnc[l](X, STE_P, mask=True)\n",
        "            dhm0_S_enc.append(dhm_S[0]); dhm1_S_enc.append(dhm_S[1]); dhm0_T_enc.append(dhm_T[0]); dhm1_T_enc.append(dhm_T[1])\n",
        "\n",
        "        X_cross1_out = self.CrossAttention1(X, STE_P, STE_F)\n",
        "\n",
        "        dhm0_S_dec, dhm1_S_dec, dhm0_T_dec, dhm1_T_dec = [], [], [], []\n",
        "\n",
        "        X_dec1_out = X_cross1_out\n",
        "        for net in self.STATBlockDec1:\n",
        "            X_dec1_out, dhm_S, dhm_T = net(X_dec1_out, STE_F, mask=True)\n",
        "            dhm0_S_dec.append(dhm_S[0]); dhm1_S_dec.append(dhm_S[1]); dhm0_T_dec.append(dhm_T[0]); dhm1_T_dec.append(dhm_T[1])\n",
        "\n",
        "        dhm0_S = torch.sum(torch.stack(dhm0_S_enc + dhm0_S_dec, dim=0), dim=0)\n",
        "        dhm1_S = torch.sum(torch.stack(dhm1_S_enc + dhm1_S_dec, dim=0), dim=0)\n",
        "        dhm0_T = torch.sum(torch.stack(dhm0_T_enc + dhm0_T_dec, dim=0), dim=0)\n",
        "        dhm1_T = torch.sum(torch.stack(dhm1_T_enc + dhm1_T_dec, dim=0), dim=0)\n",
        "\n",
        "        X_dec1_out = self.FC_dec1_2(F.relu(self.FC_dec1_1(X_dec1_out)))\n",
        "\n",
        "        if flag in ('train', 'val'):\n",
        "            X_cross2_out = self.CrossAttention2(X_enc_out_L1, STE_P, STE_H)\n",
        "            X_dec2_out = X_cross2_out\n",
        "            for net in self.STATBlockDec2:\n",
        "                 X_dec2_out = net(X_dec2_out, STE_H, mask=True)\n",
        "            X_dec2_out = self.FC_dec2_2(F.relu(self.FC_dec2_1(X_dec2_out)))\n",
        "            return X_dec1_out.squeeze(3), X_dec2_out.squeeze(3), dhm0_S, dhm1_S, dhm0_T, dhm1_T\n",
        "\n",
        "        # --- THIS IS THE CORRECTED LINE ---\n",
        "        # The original code returns 5 items for the test flag, not 6.\n",
        "        if flag == 'test':\n",
        "            return X_dec1_out.squeeze(3), dhm0_S, dhm1_S, dhm0_T, dhm1_T\n",
        "\n",
        "def mae_loss(pred, label, device):\n",
        "    mask = (label != 0).type(torch.FloatTensor).to(device)\n",
        "    mask /= torch.mean(mask)\n",
        "    mask[torch.isnan(mask)] = 0\n",
        "    loss = torch.abs(pred - label) * mask\n",
        "    loss[torch.isnan(loss)] = 0\n",
        "    return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnZB7cwOpft8",
        "outputId": "306936a0-e256-415a-8a87-086e7690e019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjacency matrix saved to /content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/youbike_adj.npy\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Preprocessing 1 - Create Adjacency Matrix\n",
        "import networkx as nx\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def get_adjacency_matrix(distance_df_filename, num_of_vertices, normalized_k=0.1):\n",
        "    A = np.zeros((int(num_of_vertices), int(num_of_vertices)), dtype=np.float32)\n",
        "    distanceA = np.full((int(num_of_vertices), int(num_of_vertices)), np.inf, dtype=np.float32)\n",
        "\n",
        "    with open(distance_df_filename, 'r') as f:\n",
        "        f.readline() # Skip header\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if len(row) != 3: continue\n",
        "            i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
        "            distanceA[i, j] = distance\n",
        "            distanceA[j, i] = distance # Make it symmetric\n",
        "\n",
        "    for i in range(num_of_vertices):\n",
        "        distanceA[i, i] = 0\n",
        "\n",
        "    std = np.std(distanceA[distanceA != np.inf])\n",
        "    adj = np.exp(-np.square(distanceA / std))\n",
        "    adj[adj < normalized_k] = 0\n",
        "    return adj\n",
        "\n",
        "# --- CONFIGURE AND RUN ---\n",
        "NUM_STATIONS = 105 # This should match your dataset\n",
        "\n",
        "# <-- UPDATE THESE LINES -->\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/\"\n",
        "DISTANCE_FILE = os.path.join(DRIVE_DATA_PATH, 'youbike_distances.csv')\n",
        "ADJ_FILE = os.path.join(DRIVE_DATA_PATH, 'youbike_adj.npy')\n",
        "\n",
        "# This part remains the same\n",
        "adjacency_matrix = get_adjacency_matrix(DISTANCE_FILE, NUM_STATIONS)\n",
        "np.save(ADJ_FILE, adjacency_matrix)\n",
        "print(f\"Adjacency matrix saved to {ADJ_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "16a6338b92bc450d8d730892867bf1df",
            "5b339cd88b954045be5014b45752cdfb",
            "c2f3db7e318e46fca22b792bfc848e3d",
            "80bd37992e394526af013573448b078f",
            "8722c391615840dcb01fdc1e4c29d88b",
            "a2b266eb3e0d4d4a8d5613d593709a6a",
            "842c3cb958f44233a94c662f21f6be28",
            "31fd00849b8244aabf2351ca8fea284a",
            "e703d88c62184850847adba5ecaeaa14",
            "e9c9cc258a944a4188938f9af96bcfcc",
            "a6f57a5b871b4fb2a53d2767482ed498"
          ]
        },
        "id": "Z9sIG3p2pGVu",
        "outputId": "f2a59e7a-43ac-4693-aa3b-6ba68c98ea8b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16a6338b92bc450d8d730892867bf1df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cell 8: Preprocessing 2 - Generate Spatial Embeddings (SE)\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/\"\n",
        "ADJ_FILE = os.path.join(DRIVE_DATA_PATH, 'youbike_adj.npy')\n",
        "SE_FILE = os.path.join(DRIVE_DATA_PATH, 'SE_youbike.txt')\n",
        "\n",
        "adj_mx = np.load(ADJ_FILE)\n",
        "graph = nx.from_numpy_array(adj_mx)\n",
        "\n",
        "# You can tune these node2vec parameters for better performance\n",
        "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
        "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "\n",
        "model.wv.save_word2vec_format(SE_FILE)\n",
        "print(f\"Spatial embeddings saved to {SE_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvIv9d-u5sJ"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Main Script - Configuration\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "class Args:\n",
        "    # Data and dimensions\n",
        "    time_slot = 10\n",
        "    H = 6          # History steps (e.g., 6 10-min intervals = 1 hour back)\n",
        "    P = 6          # Present steps (input sequence length, 1 hour)\n",
        "    F = 6          # Future steps to predict (1 hour ahead)\n",
        "    L = 2           # Number of STAT layers\n",
        "    K = 3           # Number of attention heads\n",
        "    d = 8           # Dimensions of each head's output\n",
        "    dataset = 'youbike' # This should match your data file names\n",
        "    train_ratio = 0.7\n",
        "    val_ratio = 0.1\n",
        "    test_ratio = 0.2\n",
        "\n",
        "    # Training hyperparameters\n",
        "    batch_size = 128\n",
        "    max_epoch = 10\n",
        "    patience = 10\n",
        "    learning_rate = 0.001\n",
        "    weight_decay = 0.0001\n",
        "\n",
        "    # Model-specific parameters\n",
        "    dhm = True      # Whether to use the Dynamic Halting Module\n",
        "    max_step = 6    # Max recurrent steps for DHM\n",
        "    epsilon = 0.0001\n",
        "    recollection_weight = 0.01 # Loss weight for the history decoder\n",
        "    dhm_weight = 0.001         # Penalty weight for the DHM\n",
        "\n",
        "    # System\n",
        "    seed = 10\n",
        "\n",
        "args = Args()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "init_seed(args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdy_ug7_vM5u"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Main Script - Load Data\n",
        "print('Loading data...')\n",
        "# This calls the loadData function defined in Cell 2\n",
        "(trainZ, trainX, trainTE, trainY, valZ, valX, valTE, valY, testZ, testX, testTE, testY, SE,\n",
        " mean, std) = loadData(args)\n",
        "\n",
        "print(f'trainX shape: {trainX.shape}, trainY shape: {trainY.shape}')\n",
        "print(f'valX shape: {valX.shape}, valY shape: {valY.shape}')\n",
        "print(f'testX shape: {testX.shape}, testY shape: {testY.shape}')\n",
        "print('Data loaded!')\n",
        "\n",
        "# Transform data to PyTorch tensors\n",
        "trainZ = torch.FloatTensor(trainZ).to(device)\n",
        "trainX = torch.FloatTensor(trainX).to(device)\n",
        "trainTE = torch.LongTensor(trainTE).to(device)\n",
        "trainY = torch.FloatTensor(trainY).to(device)\n",
        "valZ = torch.FloatTensor(valZ).to(device)\n",
        "valX = torch.FloatTensor(valX).to(device)\n",
        "valTE = torch.LongTensor(valTE).to(device)\n",
        "valY = torch.FloatTensor(valY).to(device)\n",
        "testZ = torch.FloatTensor(testZ).to(device)\n",
        "testX = torch.FloatTensor(testX).to(device)\n",
        "testTE = torch.LongTensor(testTE).to(device)\n",
        "testY = torch.FloatTensor(testY).to(device)\n",
        "SE = torch.FloatTensor(SE).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kpq4aY79vYpY",
        "outputId": "a04acd9b-0a4a-40c0-f27b-1c5fcc681f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Training Model ****\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 3. None expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-888645771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Calculate all metrics for the entire validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_all_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Append metrics to lists for potential plotting later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1233605808.py\u001b[0m in \u001b[0;36mcalculate_all_metrics\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Calculates MAE, MSE, RMSE, and R-squared.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# R2 score requires multi-output='uniform_average' for multi-dimensional arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[0;32m--> 565\u001b[0;31m         _check_reg_targets_with_floating_dtype(\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdtype_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_matching_floating_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
          ]
        }
      ],
      "source": [
        "# Cell 11 (Fully Corrected): Main Script - Training and Validation Loop\n",
        "\n",
        "# --- Initialize Model and Optimizer ---\n",
        "TEmbsize = (24 * 60 // 10) + 7 # Using 10-minute interval\n",
        "hidden_size = args.K * args.d\n",
        "num_sensor = trainX.shape[-1]\n",
        "\n",
        "bi_stat = BISTAT(\n",
        "    args.K, args.d, SE.shape[1], TEmbsize, args.P, args.F, args.H,\n",
        "    num_sensor, args.L, args.epsilon, hidden_size, args.max_step, args.dhm, device,\n",
        "    input_dims=1 # FIX 1: Explicitly set input features to 1\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(bi_stat.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "# Initialize model weights\n",
        "for p in bi_stat.parameters():\n",
        "   if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "   else: nn.init.uniform_(p)\n",
        "\n",
        "# --- Training ---\n",
        "print('**** Training Model ****')\n",
        "num_train = trainX.shape[0]\n",
        "num_val = valX.shape[0]\n",
        "wait = 0\n",
        "val_loss_min = np.inf\n",
        "\n",
        "# --- Lists to store metrics for each epoch ---\n",
        "val_mae_per_epoch = []\n",
        "val_mse_per_epoch = []\n",
        "val_rmse_per_epoch = []\n",
        "val_r2_per_epoch = []\n",
        "\n",
        "# --- Define Checkpoint Path ---\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/Youbike_Master_Project/BiSTAT_Checkpoints/\"\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True) # Creates the directory if needed\n",
        "MODEL_FILE = os.path.join(CHECKPOINT_PATH, f'BISTAT_{args.dataset}.pt')\n",
        "\n",
        "for epoch in range(args.max_epoch):\n",
        "    if wait >= args.patience:\n",
        "        print(f'Early stopping at epoch: {epoch}')\n",
        "        break\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    train_loss = 0\n",
        "    num_batch = math.ceil(num_train / args.batch_size)\n",
        "    bi_stat.train()\n",
        "    for batch_idx in range(num_batch):\n",
        "        optimizer.zero_grad()\n",
        "        start_idx = batch_idx * args.batch_size\n",
        "        end_idx = min(num_train, (batch_idx + 1) * args.batch_size)\n",
        "        batchX, batchTE = trainX[start_idx:end_idx], trainTE[start_idx:end_idx]\n",
        "        batchlabel1, batchlabel2 = trainY[start_idx:end_idx], trainZ[start_idx:end_idx]\n",
        "        pred1, pred2, dhm0_S, dhm1_S, dhm0_T, dhm1_T = bi_stat(batchX, SE, batchTE, flag='train')\n",
        "        loss_dec1 = mae_loss(pred1, batchlabel1, device)\n",
        "        loss_dec2 = mae_loss(pred2, batchlabel2, device)\n",
        "        loss_dhm = torch.mean(dhm0_S + dhm1_S) + torch.mean(dhm0_T + dhm1_T)\n",
        "        batchloss = loss_dec1 + args.recollection_weight * loss_dec2 + args.dhm_weight * loss_dhm\n",
        "        batchloss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += batchloss.item() * (end_idx - start_idx)\n",
        "    train_loss /= num_train\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    bi_stat.eval()\n",
        "    val_preds, val_trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(math.ceil(num_val / args.batch_size)):\n",
        "            start_idx = batch_idx * args.batch_size\n",
        "            end_idx = min(num_val, (batch_idx + 1) * args.batch_size)\n",
        "            batchX, batchTE, batchlabel1 = valX[start_idx:end_idx], valTE[start_idx:end_idx], valY[start_idx:end_idx]\n",
        "            pred1, _, _, _, _, _ = bi_stat(batchX, SE, batchTE, flag='val')\n",
        "            val_preds.append(pred1.cpu().numpy())\n",
        "            val_trues.append(batchlabel1.cpu().numpy())\n",
        "\n",
        "    val_preds = np.concatenate(val_preds, axis=0)\n",
        "    val_trues = np.concatenate(val_trues, axis=0)\n",
        "\n",
        "    # FIX 2: Reshape 3D arrays to 2D for scikit-learn metrics\n",
        "    num_samples = val_trues.shape[0]\n",
        "    val_trues_2d = val_trues.reshape(num_samples, -1)\n",
        "    val_preds_2d = val_preds.reshape(num_samples, -1)\n",
        "\n",
        "    # Calculate all metrics on the reshaped 2D arrays\n",
        "    mae, mse, rmse, r2 = calculate_all_metrics(val_trues_2d, val_preds_2d)\n",
        "\n",
        "    val_mae_per_epoch.append(mae)\n",
        "    val_mse_per_epoch.append(mse)\n",
        "    val_rmse_per_epoch.append(rmse)\n",
        "    val_r2_per_epoch.append(r2)\n",
        "\n",
        "    print(f\"--- Epoch {epoch+1}/{args.max_epoch} ---\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Metrics -> MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "    if mae <= val_loss_min:\n",
        "        print(f'---> Validation MAE decreased from {val_loss_min:.4f} to {mae:.4f}, saving model.')\n",
        "        wait = 0\n",
        "        val_loss_min = mae\n",
        "        torch.save(bi_stat.state_dict(), MODEL_FILE)\n",
        "    else:\n",
        "        wait += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iT_aBLttvnGY",
        "outputId": "18818d0e-a65c-49af-e7c6-e0595812a521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**** Testing Model ****\n",
            "Model restored from /content/drive/MyDrive/Youbike_Master_Project/BiSTAT_Checkpoints/BISTAT_youbike.pt!\n",
            "\n",
            "--- Overall Test Performance (Average of all horizons) ---\n",
            "Overall --> MAE: 0.0895, MSE: 0.0257, RMSE: 0.1603, R²: 0.6873\n",
            "\n",
            "--- Performance per Prediction Horizon ---\n",
            "Horizon 01 ----> MAE: 0.0524, MSE: 0.0105, RMSE: 0.1023, R²: 0.8734\n",
            "Horizon 02 ----> MAE: 0.0714, MSE: 0.0175, RMSE: 0.1321, R²: 0.7882\n",
            "Horizon 03 ----> MAE: 0.0860, MSE: 0.0236, RMSE: 0.1536, R²: 0.7134\n",
            "Horizon 04 ----> MAE: 0.0985, MSE: 0.0291, RMSE: 0.1706, R²: 0.6458\n",
            "Horizon 05 ----> MAE: 0.1095, MSE: 0.0343, RMSE: 0.1853, R²: 0.5817\n",
            "Horizon 06 ----> MAE: 0.1193, MSE: 0.0392, RMSE: 0.1981, R²: 0.5210\n"
          ]
        }
      ],
      "source": [
        "# The Final, Complete Cell for Testing, Analysis, and Plotting\n",
        "\n",
        "# ===================================================================\n",
        "# PART 0: Load Timestamps for Plotting\n",
        "# ===================================================================\n",
        "print(\"**** Loading Timestamps for Plotting ****\")\n",
        "# This is the path to your ORIGINAL feature-engineered data file\n",
        "TIMESTAMP_FILE_PATH = \"/content/drive/MyDrive/Youbike_Master_Project/YouBike_Demand_Forecast/data/gongguan_model_ready_features.parquet.gz\"\n",
        "\n",
        "# Efficiently load only the 'time' column into a new dataframe\n",
        "timestamps_df = pd.read_parquet(TIMESTAMP_FILE_PATH, columns=['time'])\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# PART 1: Run Predictions on the Test Set\n",
        "# ===================================================================\n",
        "print('\\n**** Testing Model ****')\n",
        "bi_stat.load_state_dict(torch.load(MODEL_FILE))\n",
        "print(f'Model restored from {MODEL_FILE}!')\n",
        "\n",
        "num_test = testX.shape[0]\n",
        "testPred = []\n",
        "\n",
        "bi_stat.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_idx in range(math.ceil(num_test / args.batch_size)):\n",
        "        start_idx = batch_idx * args.batch_size\n",
        "        end_idx = min(num_test, (batch_idx + 1) * args.batch_size)\n",
        "        batchX, batchTE = testX[start_idx:end_idx], testTE[start_idx:end_idx]\n",
        "        batchpred, _, _, _, _ = bi_stat(batchX, SE, batchTE, flag='test')\n",
        "        testPred.append(batchpred.detach().cpu().numpy())\n",
        "\n",
        "testPred = np.concatenate(testPred, axis=0)\n",
        "testY_truth = testY.cpu().numpy()\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# PART 2: Calculate and Print All Metrics\n",
        "# ===================================================================\n",
        "# --- Overall Average Metrics ---\n",
        "num_test_samples = testY_truth.shape[0]\n",
        "testY_truth_2d = testY_truth.reshape(num_test_samples, -1)\n",
        "testPred_2d = testPred.reshape(num_test_samples, -1)\n",
        "mae, mse, rmse, r2 = calculate_all_metrics(testY_truth_2d, testPred_2d)\n",
        "print('\\n--- Overall Test Performance (Average of all horizons) ---')\n",
        "print(f'Overall --> MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}')\n",
        "\n",
        "# --- Per-Horizon Metrics ---\n",
        "print('\\n--- Performance per Prediction Horizon ---')\n",
        "for q in range(args.F):\n",
        "    y_true_horizon = testY_truth[:, q, :]\n",
        "    y_pred_horizon = testPred[:, q, :]\n",
        "    mae_h, mse_h, rmse_h, r2_h = calculate_all_metrics(y_true_horizon, y_pred_horizon)\n",
        "    print(f'Horizon {q+1:02d} ----> MAE: {mae_h:.4f}, MSE: {mse_h:.4f}, RMSE: {rmse_h:.4f}, R²: {r2_h:.4f}')\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# PART 3: Find Best and Worst Performing Stations\n",
        "# ===================================================================\n",
        "print(\"\\n**** Analyzing Performance per Station ****\")\n",
        "station_errors = np.mean(np.abs(testPred - testY_truth), axis=(0, 1))\n",
        "sorted_station_indices = np.argsort(station_errors)\n",
        "best_3_indices = sorted_station_indices[:3]\n",
        "worst_3_indices = sorted_station_indices[-3:]\n",
        "\n",
        "print(f\"\\nTop 3 Best Performing Stations (by MAE):\")\n",
        "for i, idx in enumerate(best_3_indices):\n",
        "    print(f\"  {i+1}. Station Index: {idx}, MAE: {station_errors[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\nTop 3 Worst Performing Stations (by MAE):\")\n",
        "for i, idx in enumerate(worst_3_indices[::-1]): # Reverse to show worst first\n",
        "    print(f\"  {i+1}. Station Index: {idx}, MAE: {station_errors[idx]:.4f}\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# PART 4: Create the Continuous, Sliding-Window Plot\n",
        "# ===================================================================\n",
        "print(\"\\n**** Generating Continuous Forecast Plot for a Single Horizon ****\")\n",
        "\n",
        "# --- Configuration ---\n",
        "station_to_plot_idx = best_3_indices[0] # Plot the best station\n",
        "horizon_to_plot = 5 # This is the t+6 forecast (1 hour ahead)\n",
        "\n",
        "# --- Extract the specific horizon data ---\n",
        "predictions_continuous = testPred[:, horizon_to_plot, station_to_plot_idx]\n",
        "actuals_continuous = testY_truth[:, horizon_to_plot, station_to_plot_idx]\n",
        "\n",
        "# --- Reconstruct Timestamps using the `timestamps_df` we just loaded ---\n",
        "num_step = timestamps_df['time'].nunique()\n",
        "train_steps = round(args.train_ratio * num_step)\n",
        "val_steps = round(args.val_ratio * num_step)\n",
        "test_start_index = train_steps + val_steps\n",
        "first_target_timestamp_index = test_start_index + args.H + args.P + horizon_to_plot\n",
        "all_timestamps = np.sort(pd.to_datetime(timestamps_df['time']).unique())\n",
        "end_timestamp_index = first_target_timestamp_index + len(actuals_continuous)\n",
        "plot_timestamps = all_timestamps[first_target_timestamp_index:end_timestamp_index]\n",
        "\n",
        "# --- Create the Plot ---\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(plot_timestamps, actuals_continuous, label='Actual Values', color='blue')\n",
        "plt.plot(plot_timestamps, predictions_continuous, label='Predicted Values', color='green', linestyle='--')\n",
        "plt.title(f'Continuous t+{horizon_to_plot+1} Forecast for Station Index {station_to_plot_idx}', fontsize=16)\n",
        "plt.xlabel('Date and Time')\n",
        "plt.ylabel('Occupancy Ratio')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rOdFrFyxFvAl"
      },
      "outputs": [],
      "source": [
        "# ADD this new cell after the testing cell\n",
        "\n",
        "print(\"\\n**** Analyzing Performance per Station ****\")\n",
        "\n",
        "# Calculate MAE for each station individually across all samples and horizons\n",
        "station_errors = np.mean(np.abs(testPred - testY_truth), axis=(0, 1))\n",
        "\n",
        "# Get the indices of the stations, sorted by their error\n",
        "sorted_station_indices = np.argsort(station_errors)\n",
        "\n",
        "best_3_indices = sorted_station_indices[:3]\n",
        "worst_3_indices = sorted_station_indices[-3:]\n",
        "\n",
        "print(f\"\\nTop 3 Best Performing Stations (by MAE):\")\n",
        "for i, idx in enumerate(best_3_indices):\n",
        "    print(f\"  {i+1}. Station Index: {idx}, MAE: {station_errors[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\nTop 3 Worst Performing Stations (by MAE):\")\n",
        "for i, idx in enumerate(worst_3_indices[::-1]): # Reverse to show worst first\n",
        "    print(f\"  {i+1}. Station Index: {idx}, MAE: {station_errors[idx]:.4f}\")\n",
        "\n",
        "# --- Plotting ---\n",
        "# Let's pick a sample prediction from the middle of the test set to visualize\n",
        "sample_idx_to_plot = len(testPred) // 2\n",
        "horizons = np.arange(1, args.F + 1)\n",
        "\n",
        "# Plot best stations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
        "fig.suptitle('3 Best Performing Stations (Sample Forecast)', fontsize=16)\n",
        "for i, station_idx in enumerate(best_3_indices):\n",
        "    axes[i].plot(horizons, testY_truth[sample_idx_to_plot, :, station_idx], 'o-', label='Actual')\n",
        "    axes[i].plot(horizons, testPred[sample_idx_to_plot, :, station_idx], 'x-', label='Predicted')\n",
        "    axes[i].set_title(f\"Station Index {station_idx}\\nMAE: {station_errors[station_idx]:.4f}\")\n",
        "    axes[i].set_xlabel(\"Forecast Horizon (10-min steps)\")\n",
        "    axes[i].set_ylabel(\"Occupancy Ratio\")\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot worst stations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
        "fig.suptitle('3 Worst Performing Stations (Sample Forecast)', fontsize=16)\n",
        "for i, station_idx in enumerate(worst_3_indices):\n",
        "    axes[i].plot(horizons, testY_truth[sample_idx_to_plot, :, station_idx], 'o-', label='Actual')\n",
        "    axes[i].plot(horizons, testPred[sample_idx_to_plot, :, station_idx], 'x-', label='Predicted')\n",
        "    axes[i].set_title(f\"Station Index {station_idx}\\nMAE: {station_errors[station_idx]:.4f}\")\n",
        "    axes[i].set_xlabel(\"Forecast Horizon (10-min steps)\")\n",
        "    axes[i].set_ylabel(\"Occupancy Ratio\")\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pf-PzOoSGBah"
      },
      "outputs": [],
      "source": [
        "# ADD this new cell to save the results\n",
        "\n",
        "print(\"\\n**** Saving Test Set Predictions and Actuals ****\")\n",
        "\n",
        "# Define the path on your Google Drive\n",
        "output_path = \"/content/drive/MyDrive/Youbike_Master_Project/predictions/BiSTAT/\"\n",
        "os.makedirs(output_path, exist_ok=True) # Ensure directory exists\n",
        "\n",
        "# Save the arrays to a single .npz file\n",
        "np.savez(\n",
        "    os.path.join(output_path, 'bistat_predictions.npz'),\n",
        "    predictions=testPred,\n",
        "    actuals=testY_truth\n",
        ")\n",
        "\n",
        "print(f\"✅ Predictions and actuals saved to: {os.path.join(output_path, 'bistat_predictions.npz')}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16a6338b92bc450d8d730892867bf1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b339cd88b954045be5014b45752cdfb",
              "IPY_MODEL_c2f3db7e318e46fca22b792bfc848e3d",
              "IPY_MODEL_80bd37992e394526af013573448b078f"
            ],
            "layout": "IPY_MODEL_8722c391615840dcb01fdc1e4c29d88b"
          }
        },
        "31fd00849b8244aabf2351ca8fea284a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b339cd88b954045be5014b45752cdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b266eb3e0d4d4a8d5613d593709a6a",
            "placeholder": "​",
            "style": "IPY_MODEL_842c3cb958f44233a94c662f21f6be28",
            "value": "Computing transition probabilities: 100%"
          }
        },
        "80bd37992e394526af013573448b078f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c9cc258a944a4188938f9af96bcfcc",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f57a5b871b4fb2a53d2767482ed498",
            "value": " 105/105 [00:00&lt;00:00, 404.26it/s]"
          }
        },
        "842c3cb958f44233a94c662f21f6be28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8722c391615840dcb01fdc1e4c29d88b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b266eb3e0d4d4a8d5613d593709a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f57a5b871b4fb2a53d2767482ed498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2f3db7e318e46fca22b792bfc848e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31fd00849b8244aabf2351ca8fea284a",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e703d88c62184850847adba5ecaeaa14",
            "value": 105
          }
        },
        "e703d88c62184850847adba5ecaeaa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9c9cc258a944a4188938f9af96bcfcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}